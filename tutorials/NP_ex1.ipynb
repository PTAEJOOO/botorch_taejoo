{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82109\\AppData\\Local\\Temp\\ipykernel_19548\\1035163680.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from ANP import *\n",
    "\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.priors import HorseshoePrior\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "print(dim)\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(RAW_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))\n",
    "\n",
    "def get_initial_points(dim, n_pts, seed=0):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ei = get_initial_points(dim, n_init)\n",
    "# Y_ei = torch.tensor(\n",
    "#     [eval_objective(x) for x in X_ei], dtype=dtype, device=device\n",
    "# ).unsqueeze(-1)\n",
    "# print(X_ei.size())\n",
    "# print(Y_ei.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GP-EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "\n",
    "# X_ei = get_initial_points(dim, n_init)\n",
    "# Y_ei = torch.tensor(\n",
    "#     [eval_objective(x) for x in X_ei], dtype=dtype, device=device\n",
    "# ).unsqueeze(-1)\n",
    "\n",
    "# while len(Y_ei) < 400:\n",
    "#     train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
    "#     likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "#     model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
    "#     mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "#     fit_gpytorch_mll(mll)\n",
    "\n",
    "#     # Create a batch\n",
    "#     ei = qExpectedImprovement(model, train_Y.max())\n",
    "#     candidate, acq_value = optimize_acqf(\n",
    "#         ei,\n",
    "#         bounds=torch.stack(\n",
    "#             [\n",
    "#                 torch.zeros(dim, dtype=dtype, device=device),\n",
    "#                 torch.ones(dim, dtype=dtype, device=device),\n",
    "#             ]\n",
    "#         ),\n",
    "#         q=batch_size,\n",
    "#         num_restarts=NUM_RESTARTS,\n",
    "#         raw_samples=RAW_SAMPLES,\n",
    "#     )\n",
    "#     Y_next = torch.tensor(\n",
    "#         [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "#     ).unsqueeze(-1)\n",
    "\n",
    "#     # Append data\n",
    "#     X_ei = torch.cat((X_ei, candidate), axis=0)\n",
    "#     Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
    "#     # print(X_ei.size(), Y_ei.size())\n",
    "\n",
    "#     # Print current status\n",
    "#     print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP-MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from math import pi\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class My_Ackley(Dataset):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "\n",
    "        # Generate data\n",
    "        self.data = []\n",
    "        self.data.append((self.train_x, self.train_y))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from neural_process import NeuralProcess\n",
    "# from training import NeuralProcessTrainer\n",
    "\n",
    "# ## NP model\n",
    "# x_dim = 20\n",
    "# y_dim = 1\n",
    "# r_dim = 50  # Dimension of representation of context points\n",
    "# z_dim = 50  # Dimension of sampled latent variable\n",
    "# h_dim = 50  # Dimension of hidden layers in encoder and decoder\n",
    "# neuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# X_np = get_initial_points(dim, n_init)\n",
    "# Y_np = torch.tensor(\n",
    "#     [eval_objective(x) for x in X_np], dtype=dtype, device=device\n",
    "# ).unsqueeze(-1)\n",
    "\n",
    "# batch_size = 2\n",
    "# num_context = 4\n",
    "# num_target = 4\n",
    "\n",
    "# ackley_dataset = My_Ackley(train_x = X_np, train_y = Y_np)\n",
    "# data_loader = DataLoader(ackley_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "# np_trainer = NeuralProcessTrainer(device, neuralprocess, optimizer,\n",
    "#                                   num_context_range=(num_context, num_context),\n",
    "#                                   num_extra_target_range=(num_target, num_target), \n",
    "#                                   print_freq=100)\n",
    "\n",
    "# neuralprocess.training = True\n",
    "# np_trainer.train(data_loader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import context_target_split\n",
    "# from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "# from botorch.acquisition.monte_carlo import MCAcquisitionFunction, qExpectedImprovement\n",
    "# from botorch.acquisition.monte_carlo import SampleReducingMCAcquisitionFunction\n",
    "# from botorch.sampling.stochastic_samplers import StochasticSampler\n",
    "# from botorch.acquisition.objective import IdentityMCObjective\n",
    "\n",
    "# # Extract a batch from data_loader\n",
    "# for batch in data_loader:\n",
    "#     break\n",
    "\n",
    "# # Use batch to create random set of context points\n",
    "# x, y = batch\n",
    "# x_context, y_context, _, _ = context_target_split(x[0:1], y[0:1], \n",
    "#                                                   num_context, \n",
    "#                                                   num_target)\n",
    "\n",
    "# # Create a set of target points corresponding to entire [-pi, pi] range\n",
    "# x_target = torch.Tensor(np.linspace(-5, 10, 100)).unsqueeze(1).unsqueeze(0)\n",
    "# for i in range(dim-1):\n",
    "#     a = torch.Tensor(np.linspace(-5, 10, 100)).unsqueeze(1).unsqueeze(0)\n",
    "#     x_target = torch.cat((x_target, a), axis=2)\n",
    "\n",
    "# best_f = Y_np.max()\n",
    "# neuralprocess.training = False\n",
    "# # sampler = SobolQMCNormalSampler(torch.Size([4]), seed=1234)\n",
    "# # sampler = StochasticSampler(torch.Size([4]), seed=1234)\n",
    "# # obj = IdentityMCObjective()\n",
    "# # acq = qExpectedImprovement(neuralprocess, best_f, sampler, obj)\n",
    "# posterior = neuralprocess.posterior(x_context, y_context, x_target)\n",
    "# # samples = sampler(posterior)\n",
    "# # print(samples.size())\n",
    "# sampler = StochasticSampler(torch.Size([4]), seed=1234)\n",
    "# identity_objective = IdentityMCObjective()\n",
    "# samples = sampler(posterior)\n",
    "# objective = identity_objective(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100, loss 9.718\n",
      "iteration 200, loss 9.692\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[56, 50]' is invalid for input of size 400",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 73\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# print(neuralprocess.z_sample.size())\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# z = neuralprocess.z_sample\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# z = z.unsqueeze(1).repeat(1, RAW_SAMPLES, 1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# print(z_flat.size())\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[0;32m     72\u001b[0m ei \u001b[38;5;241m=\u001b[39m qExpectedImprovement(neuralprocess, best_f, sampler, obj)\n\u001b[1;32m---> 73\u001b[0m candidate, acq_value \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mei\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_RESTARTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRAW_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m## MC-based\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# neuralprocess.training = False\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# for batch in data_loader:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# posterior = neuralprocess.posterior(x_context, y_context, x_target)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# samples = sampler(posterior)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m Y_next \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m    107\u001b[0m     [eval_objective(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m candidate], dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    108\u001b[0m )\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\optim\\optimize.py:550\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[0;32m    528\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[0;32m    529\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[0;32m    530\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[0;32m    549\u001b[0m )\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\optim\\optimize.py:572\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\optim\\optimize.py:269\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mbatch_initial_conditions\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument `acq_function` to anonymous call.\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mget_ic_generator()(\n\u001b[0;32m    270\u001b[0m         acq_function\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39macq_function,\n\u001b[0;32m    271\u001b[0m         bounds\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[0;32m    272\u001b[0m         q\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mq,\n\u001b[0;32m    273\u001b[0m         num_restarts\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mnum_restarts,\n\u001b[0;32m    274\u001b[0m         raw_samples\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mraw_samples,\n\u001b[0;32m    275\u001b[0m         fixed_features\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mfixed_features,\n\u001b[0;32m    276\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    277\u001b[0m         inequality_constraints\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39minequality_constraints,\n\u001b[0;32m    278\u001b[0m         equality_constraints\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mequality_constraints,\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mic_gen_kwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    282\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    284\u001b[0m     opt_inputs\u001b[38;5;241m.\u001b[39mnum_restarts\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mnonlinear_inequality_constraints\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    287\u001b[0m )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_batch_candidates\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[38;5;167;01mWarning\u001b[39;00m]]:\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\optim\\initializers.py:389\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    388\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m batch_limit, X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 389\u001b[0m     Y_rnd_curr \u001b[38;5;241m=\u001b[39m \u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_rnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    392\u001b[0m     Y_rnd_list\u001b[38;5;241m.\u001b[39mappend(Y_rnd_curr)\n\u001b[0;32m    393\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_limit\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\utils\\transforms.py:303\u001b[0m, in \u001b[0;36mconcatenate_pending_points.<locals>.decorated\u001b[1;34m(cls, X, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([X, match_batch_shape(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending, X)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mcls\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\utils\\transforms.py:257\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[1;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[0;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 257\u001b[0m output \u001b[38;5;241m=\u001b[39m method(acqf, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_fully_bayesian(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    261\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\acquisition\\monte_carlo.py:272\u001b[0m, in \u001b[0;36mSampleReducingMCAcquisitionFunction.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;129m@concatenate_pending_points\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;129m@t_batch_mode_transform\u001b[39m()\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the acquisition value associated with the input `X`. Weighs the\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    acquisition utility values by smoothed constraint indicators if `constraints`\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    was passed to the constructor of the class. Applies `self.sample_reduction` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m        batch shape of model and input `X`.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m     non_reduced_acqval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_reduced_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_reduction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_q_reduction(non_reduced_acqval))\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\acquisition\\monte_carlo.py:285\u001b[0m, in \u001b[0;36mSampleReducingMCAcquisitionFunction._non_reduced_forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_non_reduced_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the constrained acquisition values at the MC-sample, q level.\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m        A Tensor with shape `sample_sample x batch_shape x q`.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     samples, obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_samples_and_objectives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     acqval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_forward(obj)  \u001b[38;5;66;03m# `sample_sample x batch_shape x q`\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_constraints(acqval\u001b[38;5;241m=\u001b[39macqval, samples\u001b[38;5;241m=\u001b[39msamples)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\botorch\\acquisition\\monte_carlo.py:118\u001b[0m, in \u001b[0;36mMCAcquisitionFunction._get_samples_and_objectives\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_samples_and_objectives\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes posterior samples and objective values at input X.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m        tensor of MC objective values with shape `sample_shape x batch_shape x q`.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_posterior_samples(posterior)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective(samples\u001b[38;5;241m=\u001b[39msamples, X\u001b[38;5;241m=\u001b[39mX)\n",
      "File \u001b[1;32mc:\\Users\\82109\\OneDrive\\바탕 화면\\lab\\code\\botorch_taejoo\\tutorials\\neural_process.py:188\u001b[0m, in \u001b[0;36mNeuralProcess.posterior\u001b[1;34m(self, X, posterior_transform)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mposterior\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, posterior_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# # At testing time, encode only context\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# mu_context, sigma_context = self.xy_to_mu_sigma(x_context, y_context)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# z_sample = q_context.rsample()\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;66;03m# Predict target points based on context\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     y_pred_mu, y_pred_sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxz_to_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m     p_y_pred \u001b[38;5;241m=\u001b[39m Normal(y_pred_mu, y_pred_sigma)\n\u001b[0;32m    190\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m TorchPosterior(p_y_pred)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\82109\\OneDrive\\바탕 화면\\lab\\code\\botorch_taejoo\\tutorials\\models.py:145\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, z)\u001b[0m\n\u001b[0;32m    143\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_points, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    144\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m num_points, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_dim)\n\u001b[1;32m--> 145\u001b[0m z_flat \u001b[38;5;241m=\u001b[39m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Input is concatenation of z with every row of x\u001b[39;00m\n\u001b[0;32m    147\u001b[0m input_pairs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_flat, z_flat), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[56, 50]' is invalid for input of size 400"
     ]
    }
   ],
   "source": [
    "## bo\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_process import NeuralProcess\n",
    "from training import NeuralProcessTrainer\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from utils import context_target_split\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
    "from botorch.sampling.stochastic_samplers import StochasticSampler\n",
    "from botorch.acquisition.objective import IdentityMCObjective\n",
    "\n",
    "# NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "# RAW_SAMPLES = 500 if not SMOKE_TEST else 4\n",
    "# N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "NUM_RESTARTS = 2\n",
    "RAW_SAMPLES = 7\n",
    "N_CANDIDATES = 4\n",
    "\n",
    "## NP model\n",
    "x_dim = 20\n",
    "y_dim = 1\n",
    "r_dim = 50  # Dimension of representation of context points\n",
    "z_dim = 50  # Dimension of sampled latent variable\n",
    "h_dim = 50  # Dimension of hidden layers in encoder and decoder\n",
    "neuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)\n",
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "\n",
    "batch_size = 8\n",
    "num_context = 4\n",
    "num_target = 4\n",
    "np_trainer = NeuralProcessTrainer(device, neuralprocess, optimizer,\n",
    "                                  num_context_range=(num_context, num_context),\n",
    "                                  num_extra_target_range=(num_target, num_target), \n",
    "                                  print_freq=100)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X_np = get_initial_points(dim, n_init)\n",
    "Y_np = torch.tensor(\n",
    "    [eval_objective(x) for x in X_np], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "# sampler = SobolQMCNormalSampler(torch.Size([batch_size, RAW_SAMPLES]), seed=1234)\n",
    "sampler = StochasticSampler(torch.Size([4]), seed=1234)\n",
    "obj = IdentityMCObjective()\n",
    "\n",
    "while len(Y_np) < 400:\n",
    "    best_f = Y_np.max() \n",
    "    train_Y = (Y_np - Y_np.mean()) / Y_np.std()\n",
    "    ackley_dataset = My_Ackley(train_x = X_np, train_y = train_Y)\n",
    "    data_loader = DataLoader(ackley_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    neuralprocess.training = True\n",
    "    np_trainer.train(data_loader, 200)\n",
    "\n",
    "    # Create a batch\n",
    "    # ei = qExpectedImprovement(neuralprocess, train_Y.max())\n",
    "    neuralprocess.training = False\n",
    "    for batch in data_loader:\n",
    "        break\n",
    "    x, y = batch\n",
    "    x_context, y_context, _, _ = context_target_split(x[0:1], y[0:1], \n",
    "                                                    num_context, \n",
    "                                                    num_target)\n",
    "    neuralprocess.set_context_for_posterior(x_context, y_context)\n",
    "    # print(neuralprocess.z_sample.size())\n",
    "    # z = neuralprocess.z_sample\n",
    "    # z = z.unsqueeze(1).repeat(1, RAW_SAMPLES, 1)\n",
    "    # print(z.size())\n",
    "    # z_flat = z.view(batch_size * RAW_SAMPLES, 50)\n",
    "    # print(z_flat.size())\n",
    "    # break\n",
    "    ei = qExpectedImprovement(neuralprocess, best_f, sampler, obj)\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        ei,\n",
    "        bounds=torch.stack(\n",
    "            [\n",
    "                torch.zeros(dim, dtype=dtype, device=device),\n",
    "                torch.ones(dim, dtype=dtype, device=device),\n",
    "            ]\n",
    "        ),\n",
    "        q=batch_size,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "    )\n",
    "\n",
    "    ## MC-based\n",
    "    # neuralprocess.training = False\n",
    "    # for batch in data_loader:\n",
    "    #     break\n",
    "\n",
    "    # # Use batch to create random set of context points\n",
    "    # x, y = batch\n",
    "    # x_context, y_context, _, _ = context_target_split(x[0:1], y[0:1], \n",
    "    #                                                 num_context, \n",
    "    #                                                 num_target)\n",
    "\n",
    "    # # Create a set of target points corresponding to entire [-pi, pi] range\n",
    "    # x_target = torch.Tensor(np.linspace(-5, 10, 100)).unsqueeze(1).unsqueeze(0)\n",
    "    # for i in range(dim-1):\n",
    "    #     a = torch.Tensor(np.linspace(-5, 10, 100)).unsqueeze(1).unsqueeze(0)\n",
    "    #     x_target = torch.cat((x_target, a), axis=2)\n",
    "\n",
    "    # posterior = neuralprocess.posterior(x_context, y_context, x_target)\n",
    "    # samples = sampler(posterior)\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Append data\n",
    "    X_np = torch.cat((X_np, candidate), axis=0)\n",
    "    Y_np = torch.cat((Y_np, Y_next), axis=0)\n",
    "    # print(X_ei.size(), Y_ei.size())\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_np)}) Best value: {Y_np.max().item():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50])\n",
      "torch.Size([2, 1, 50])\n",
      "torch.Size([2, 10, 50])\n",
      "torch.Size([20, 50])\n"
     ]
    }
   ],
   "source": [
    "z = torch.randn(2, 50)\n",
    "print(z.size())\n",
    "num_points = 10\n",
    "z = z.unsqueeze(1)\n",
    "print(z.size())\n",
    "z = z.repeat(1, num_points, 1)\n",
    "print(z.size())\n",
    "z_flat = z.view(2 * num_points, 50)\n",
    "print(z_flat.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botorch_ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
