{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "1bc3d568-b16a-4fe5-9667-c0e187f9a366",
        "showInput": false
      },
      "source": [
        "## BO with TuRBO-1 and TS/qEI\n",
        "\n",
        "In this tutorial, we show how to implement Trust Region Bayesian Optimization (TuRBO) [1] in a closed loop in BoTorch.\n",
        "\n",
        "This implementation uses one trust region (TuRBO-1) and supports either parallel expected improvement (qEI) or Thompson sampling (TS). We optimize the $20D$ Ackley function on the domain $[-5, 10]^{20}$ and show that TuRBO-1 outperforms qEI as well as Sobol.\n",
        "\n",
        "Since botorch assumes a maximization problem, we will attempt to maximize $-f(x)$ to achieve $\\max_x -f(x)=0$.\n",
        "\n",
        "[1]: [Eriksson, David, et al. Scalable global optimization via local Bayesian optimization. Advances in Neural Information Processing Systems. 2019](https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921563794,
        "executionStopTime": 1674921566438,
        "originalKey": "c11881c9-13f5-4e35-bdc8-b8f817089713",
        "requestMsgId": "b21eda64-89d8-461f-a9d1-57117892e0c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\82109\\anaconda3\\envs\\botorch_ex\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "from botorch.acquisition import qExpectedImprovement\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.generation import MaxPosteriorSampling\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.test_functions import Ackley\n",
        "from botorch.utils.transforms import unnormalize\n",
        "from torch.quasirandom import SobolEngine\n",
        "\n",
        "import gpytorch\n",
        "from gpytorch.constraints import Interval\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.priors import HorseshoePrior\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.double\n",
        "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5be02873-2895-4451-8bf6-35e3cd0e6f99",
        "showInput": false
      },
      "source": [
        "## Optimize the 20-dimensional Ackley function\n",
        "\n",
        "The goal is to minimize the popular Ackley function:\n",
        "\n",
        "$f(x_1,\\ldots,x_d) = -20\\exp\\left(-0.2 \\sqrt{\\frac{1}{d} \\sum_{j=1}^d x_j^2} \\right) -\\exp \\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(2 \\pi x_j) \\right) + 20 + e$\n",
        "\n",
        "over the domain  $[-5, 10]^{20}$.  The global optimal value of $0$ is attained at $x_1 = \\ldots = x_d = 0$.\n",
        "\n",
        "As mentioned above, since botorch assumes a maximization problem, we instead maximize $-f(x)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921566576,
        "executionStopTime": 1674921566582,
        "originalKey": "069fba29-e308-4a40-b92e-b1a5bdc8dcd8",
        "requestMsgId": "40b2ab4c-067e-4e9f-9330-93dcda5f3e8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ackley()\n",
            "tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
            "        -5., -5., -5., -5., -5., -5.], dtype=torch.float64)\n",
            "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
            "        10., 10., 10., 10., 10., 10.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
        "print(fun)\n",
        "fun.bounds[0, :].fill_(-5)\n",
        "fun.bounds[1, :].fill_(10)\n",
        "dim = fun.dim\n",
        "lb, ub = fun.bounds\n",
        "print(lb)\n",
        "print(ub)\n",
        "\n",
        "batch_size = 4\n",
        "n_init = 2 * dim\n",
        "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
        "\n",
        "\n",
        "def eval_objective(x):\n",
        "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
        "    return fun(unnormalize(x, fun.bounds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6e19c4b3-1364-4789-833d-c7ae648e7a78",
        "showInput": false
      },
      "source": [
        "## Maintain the TuRBO state\n",
        "TuRBO needs to maintain a state, which includes the length of the trust region, success and failure counters, success and failure tolerance, etc. \n",
        "\n",
        "In this tutorial we store the state in a dataclass and update the state of TuRBO after each batch evaluation. \n",
        "\n",
        "**Note**: These settings assume that the domain has been scaled to $[0, 1]^d$ and that the same batch size is used for each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921566718,
        "executionStopTime": 1674921566731,
        "originalKey": "4c419a40-d6cf-43de-8c60-e8445c3ca473",
        "requestMsgId": "5fb06df5-5815-47f9-bfa5-73155751345f"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TurboState:\n",
        "    dim: int\n",
        "    batch_size: int\n",
        "    length: float = 0.8\n",
        "    length_min: float = 0.5**7\n",
        "    length_max: float = 1.6\n",
        "    failure_counter: int = 0\n",
        "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
        "    success_counter: int = 0\n",
        "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
        "    best_value: float = -float(\"inf\")\n",
        "    restart_triggered: bool = False\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.failure_tolerance = math.ceil(\n",
        "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
        "        )\n",
        "\n",
        "\n",
        "def update_state(state, Y_next):\n",
        "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
        "        state.success_counter += 1\n",
        "        state.failure_counter = 0\n",
        "    else:\n",
        "        state.success_counter = 0\n",
        "        state.failure_counter += 1\n",
        "\n",
        "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
        "        state.length = min(2.0 * state.length, state.length_max)\n",
        "        state.success_counter = 0\n",
        "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
        "        state.length /= 2.0\n",
        "        state.failure_counter = 0\n",
        "\n",
        "    state.best_value = max(state.best_value, max(Y_next).item())\n",
        "    if state.length < state.length_min:\n",
        "        state.restart_triggered = True\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "e03f6fa1-83d1-4f7e-8dfd-0a0a53a9ad1c",
        "showInput": false
      },
      "source": [
        "## Take a look at the state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921566859,
        "executionStopTime": 1674921566868,
        "originalKey": "e06a71f5-ab79-4c11-a798-2dd5f3cf40e1",
        "requestMsgId": "af20e76d-b6b3-4f59-82ae-e1d3a3159b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TurboState(dim=20, batch_size=4, length=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, failure_tolerance=5, success_counter=0, success_tolerance=10, best_value=-inf, restart_triggered=False)\n"
          ]
        }
      ],
      "source": [
        "state = TurboState(dim=dim, batch_size=batch_size)\n",
        "print(state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "9fc2a1a5-1b3e-429a-933f-49739c0e9a6b",
        "showInput": false
      },
      "source": [
        "## Generate initial points\n",
        "This generates an initial set of Sobol points that we use to start of the BO loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921567266,
        "executionStopTime": 1674921567271,
        "originalKey": "f0a7d80a-efba-4b9d-b5bc-64fdf62d0e99",
        "requestMsgId": "890e6347-f465-428c-a332-f6e3bbe34aa6"
      },
      "outputs": [],
      "source": [
        "def get_initial_points(dim, n_pts, seed=0):\n",
        "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
        "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
        "    return X_init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "d7ed19a9-4662-496c-880b-c2e0717c4117",
        "showInput": false
      },
      "source": [
        "## Generate new batch\n",
        "Given the current `state` and a probabilistic (GP) `model` built from observations `X` and `Y`, we generate a new batch of points.  \n",
        "\n",
        "This method works on the domain $[0, 1]^d$, so make sure to not pass in observations from the true domain.  `unnormalize` is called before the true function is evaluated which will first map the points back to the original domain.\n",
        "\n",
        "We support either TS and qEI which can be specified via the `acqf` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921567409,
        "executionStopTime": 1674921567429,
        "originalKey": "f4a1f540-1959-4f95-92b1-696525a50347",
        "requestMsgId": "90e9fc43-786b-4027-b89e-f76dc8e472f0"
      },
      "outputs": [],
      "source": [
        "def generate_batch(\n",
        "    state,\n",
        "    model,  # GP model\n",
        "    X,  # Evaluated points on the domain [0, 1]^d\n",
        "    Y,  # Function values\n",
        "    batch_size,\n",
        "    n_candidates=None,  # Number of candidates for Thompson sampling\n",
        "    num_restarts=10,\n",
        "    raw_samples=512,\n",
        "    acqf=\"ts\",  # \"ei\" or \"ts\"\n",
        "):\n",
        "    assert acqf in (\"ts\", \"ei\")\n",
        "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
        "    if n_candidates is None:\n",
        "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
        "\n",
        "    # Scale the TR to be proportional to the lengthscales\n",
        "    x_center = X[Y.argmax(), :].clone()\n",
        "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
        "    weights = weights / weights.mean()\n",
        "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
        "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
        "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
        "\n",
        "    if acqf == \"ts\":\n",
        "        dim = X.shape[-1]\n",
        "        sobol = SobolEngine(dim, scramble=True)\n",
        "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
        "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
        "\n",
        "        # Create a perturbation mask\n",
        "        prob_perturb = min(20.0 / dim, 1.0)\n",
        "        mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
        "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
        "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
        "\n",
        "        # Create candidate points from the perturbations and the mask\n",
        "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
        "        X_cand[mask] = pert[mask]\n",
        "\n",
        "        # Sample on the candidate points\n",
        "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
        "        with torch.no_grad():  # We don't need gradients when using TS\n",
        "            X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
        "\n",
        "    elif acqf == \"ei\":\n",
        "        ei = qExpectedImprovement(model, train_Y.max())\n",
        "        X_next, acq_value = optimize_acqf(\n",
        "            ei,\n",
        "            bounds=torch.stack([tr_lb, tr_ub]),\n",
        "            q=batch_size,\n",
        "            num_restarts=num_restarts,\n",
        "            raw_samples=raw_samples,\n",
        "        )\n",
        "\n",
        "    return X_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FLOW CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([40, 20])\n",
            "tensor(33)\n",
            "tensor([0.8516, 0.0402, 0.3704, 0.3481, 0.1430, 0.2988, 0.4283, 0.3955, 0.5193,\n",
            "        0.4953, 0.1215, 0.7439, 0.0119, 0.6467, 0.0946, 0.3786, 0.7548, 0.2294,\n",
            "        0.2794, 0.6408], dtype=torch.float64)\n",
            "--------------------------------------------------------------------------------\n",
            "tensor([4.0000, 1.5602, 4.0000, 2.6970, 1.7043, 4.0000, 4.0000, 2.7427, 4.0000,\n",
            "        4.0000, 0.8564, 4.0000, 4.0000, 4.0000, 1.4838, 4.0000, 1.8344, 0.7750,\n",
            "        1.2042, 4.0000], dtype=torch.float64, grad_fn=<SqueezeBackward0>)\n",
            "--------------------------------------------------------------------------------\n",
            "tensor([4.0000, 1.5602, 4.0000, 2.6970, 1.7043, 4.0000, 4.0000, 2.7427, 4.0000,\n",
            "        4.0000, 0.8564, 4.0000, 4.0000, 4.0000, 1.4838, 4.0000, 1.8344, 0.7750,\n",
            "        1.2042, 4.0000], dtype=torch.float64)\n",
            "tensor([1.3592, 0.5302, 1.3592, 0.9165, 0.5791, 1.3592, 1.3592, 0.9320, 1.3592,\n",
            "        1.3592, 0.2910, 1.3592, 1.3592, 1.3592, 0.5042, 1.3592, 0.6233, 0.2634,\n",
            "        0.4092, 1.3592], dtype=torch.float64)\n",
            "tensor([1.5465, 0.6032, 1.5465, 1.0428, 0.6590, 1.5465, 1.5465, 1.0604, 1.5465,\n",
            "        1.5465, 0.3311, 1.5465, 1.5465, 1.5465, 0.5737, 1.5465, 0.7092, 0.2997,\n",
            "        0.4656, 1.5465], dtype=torch.float64)\n",
            "--------------------------------------------------------------------------------\n",
            "tensor([0.2330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.1253, 0.0000, 0.0281, 0.0000, 0.0000, 0.4711, 0.1095,\n",
            "        0.0932, 0.0222], dtype=torch.float64)\n",
            "tensor([1.0000, 0.2815, 0.9890, 0.7652, 0.4066, 0.9174, 1.0000, 0.8196, 1.0000,\n",
            "        1.0000, 0.2539, 1.0000, 0.6305, 1.0000, 0.3241, 0.9972, 1.0000, 0.3493,\n",
            "        0.4656, 1.0000], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "X_turbo = get_initial_points(dim, n_init)\n",
        "Y_turbo = torch.tensor(\n",
        "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
        ").unsqueeze(-1)\n",
        "\n",
        "print(X_turbo.shape)\n",
        "print(Y_turbo.argmax())\n",
        "print(X_turbo[Y_turbo.argmax(), :])\n",
        "print(\"-\"*80)\n",
        "\n",
        "train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
        "likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
        "covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
        "    MaternKernel(\n",
        "        nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0)\n",
        "    )\n",
        ")\n",
        "model = SingleTaskGP(\n",
        "    X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood\n",
        ")\n",
        "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "fit_gpytorch_mll(mll)\n",
        "\n",
        "# Scale the TR to be proportional to the lengthscales\n",
        "x_center = X_turbo[Y_turbo.argmax(), :].clone()\n",
        "weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
        "print(weights)\n",
        "weights = weights / weights.mean()\n",
        "print(weights)\n",
        "weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
        "print(weights)\n",
        "print(\"-\"*80)\n",
        "tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
        "tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
        "print(tr_lb)\n",
        "print(tr_ub)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4000, 20])\n",
            "tensor([0.4270, 0.4880, 0.5407, 0.4701, 0.9024, 0.0278, 0.9955, 0.1911, 0.7640,\n",
            "        0.3343, 0.9478, 0.1093, 0.9273, 0.8179, 0.2646, 0.9623, 0.7874, 0.0266,\n",
            "        0.1685, 0.5184], dtype=torch.float64)\n",
            "tensor([0.6858, 0.2148, 0.4166, 0.3517, 0.4900, 0.0195, 0.8247, 0.1520, 0.7305,\n",
            "        0.3627, 0.4942, 0.4156, 0.3819, 0.8628, 0.1308, 0.7492, 0.8629, 0.0167,\n",
            "        0.1145, 0.6343], dtype=torch.float64)\n",
            "--------------------------------------------------------------------------------\n",
            "1.0\n",
            "torch.Size([4000, 20])\n",
            "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True])\n",
            "tensor([], dtype=torch.int64)\n",
            "torch.Size([4000, 20])\n",
            "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True])\n",
            "--------------------------------------------------------------------------------\n",
            "torch.Size([4000, 20])\n",
            "tensor([0.8516, 0.0402, 0.3704, 0.3481, 0.1430, 0.2988, 0.4283, 0.3955, 0.5193,\n",
            "        0.4953, 0.1215, 0.7439, 0.0119, 0.6467, 0.0946, 0.3786, 0.7548, 0.2294,\n",
            "        0.2794, 0.6408], dtype=torch.float64)\n",
            "tensor([0.6858, 0.2148, 0.4166, 0.3517, 0.4900, 0.0195, 0.8247, 0.1520, 0.7305,\n",
            "        0.3627, 0.4942, 0.4156, 0.3819, 0.8628, 0.1308, 0.7492, 0.8629, 0.0167,\n",
            "        0.1145, 0.6343], dtype=torch.float64)\n",
            "--------------------------------------------------------------------------------\n",
            "TS result\n",
            "torch.Size([4, 20])\n",
            "tensor([0.5952, 0.3453, 0.0792, 0.2374, 0.2170, 0.4825, 0.1427, 0.1782, 0.2153,\n",
            "        0.4674, 0.1633, 0.5196, 0.3274, 0.3530, 0.1417, 0.4057, 0.4766, 0.1871,\n",
            "        0.0801, 0.4754], dtype=torch.float64)\n",
            "EI result\n",
            "torch.Size([4, 20])\n",
            "tensor([0.4516, 0.3485, 0.2650, 0.1997, 0.0000, 0.4117, 0.2339, 0.0000, 0.2474,\n",
            "        0.5112, 0.0000, 0.3439, 0.0000, 0.2467, 0.0684, 0.0172, 0.3548, 0.0929,\n",
            "        0.0000, 0.6962], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "n_candidates = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
        "dim = X_turbo.shape[-1]\n",
        "sobol = SobolEngine(dim, scramble=True)\n",
        "pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
        "print(pert.shape)\n",
        "print(pert[0])\n",
        "pert = tr_lb + (tr_ub - tr_lb) * pert\n",
        "print(pert[0])\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create a perturbation mask\n",
        "prob_perturb = min(20.0 / dim, 1.0)\n",
        "print(prob_perturb)\n",
        "mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
        "print(mask.shape)\n",
        "print(mask[0])\n",
        "ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
        "print(ind)\n",
        "mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
        "print(mask.shape)\n",
        "print(mask[0])\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create candidate points from the perturbations and the mask\n",
        "X_cand = x_center.expand(n_candidates, dim).clone()\n",
        "print(X_cand.shape)\n",
        "print(X_cand[0])\n",
        "X_cand[mask] = pert[mask]\n",
        "print(X_cand[0])\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Sample on the candidate points\n",
        "thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
        "with torch.no_grad():  # We don't need gradients when using TS\n",
        "    X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
        "    print(\"TS result\")\n",
        "    print(X_next.shape)\n",
        "    print(X_next[0])\n",
        "\n",
        "num_restarts = 10 if not SMOKE_TEST else 2\n",
        "raw_samples = 512 if not SMOKE_TEST else 4\n",
        "ei = qExpectedImprovement(model, train_Y.max())\n",
        "X_next, acq_value = optimize_acqf(\n",
        "    ei,\n",
        "    bounds=torch.stack([tr_lb, tr_ub]),\n",
        "    q=batch_size,\n",
        "    num_restarts=num_restarts,\n",
        "    raw_samples=raw_samples,\n",
        ")\n",
        "print(\"EI result\")\n",
        "print(X_next.shape)\n",
        "print(X_next[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6b3dceba-35f5-4678-b21a-3b4ca22d3190",
        "showInput": false
      },
      "source": [
        "## Optimization loop\n",
        "This simple loop runs one instance of TuRBO-1 with Thompson sampling until convergence.\n",
        "\n",
        "TuRBO-1 is a local optimizer that can be used for a fixed evaluation budget in a multi-start fashion.  Once TuRBO converges, `state[\"restart_triggered\"]` will be set to true and the run should be aborted.  If you want to run more evaluations with TuRBO, you simply generate a new set of initial points and then keep generating batches until convergence or when the evaluation budget has been exceeded.  It's important to note that evaluations from previous instances are discarded when TuRBO restarts.\n",
        "\n",
        "NOTE: We use a `SingleTaskGP` with a noise constraint to keep the noise from getting too large as the problem is noise-free. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921567583,
        "executionStopTime": 1674921663734,
        "originalKey": "89258ea0-2a0c-4b88-8606-79ed531f0d97",
        "requestMsgId": "98ebf52b-fddf-485c-a250-d857b501eb19"
      },
      "outputs": [],
      "source": [
        "X_turbo = get_initial_points(dim, n_init)\n",
        "Y_turbo = torch.tensor(\n",
        "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
        ").unsqueeze(-1)\n",
        "\n",
        "state = TurboState(dim, batch_size=batch_size)\n",
        "\n",
        "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
        "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
        "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "while not state.restart_triggered:  # Run until TuRBO converges\n",
        "    # Fit a GP model\n",
        "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
        "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
        "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
        "        MaternKernel(\n",
        "            nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0)\n",
        "        )\n",
        "    )\n",
        "    model = SingleTaskGP(\n",
        "        X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood\n",
        "    )\n",
        "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "\n",
        "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
        "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
        "        # Fit the model\n",
        "        fit_gpytorch_mll(mll)\n",
        "\n",
        "        # Create a batch\n",
        "        X_next = generate_batch(\n",
        "            state=state,\n",
        "            model=model,\n",
        "            X=X_turbo,\n",
        "            Y=train_Y,\n",
        "            batch_size=batch_size,\n",
        "            n_candidates=N_CANDIDATES,\n",
        "            num_restarts=NUM_RESTARTS,\n",
        "            raw_samples=RAW_SAMPLES,\n",
        "            acqf=\"ts\",\n",
        "        )\n",
        "\n",
        "    Y_next = torch.tensor(\n",
        "        [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
        "    ).unsqueeze(-1)\n",
        "\n",
        "    # Update state\n",
        "    state = update_state(state=state, Y_next=Y_next)\n",
        "\n",
        "    # Append data\n",
        "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
        "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
        "\n",
        "    # Print current status\n",
        "    print(\n",
        "        f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "518bbb5e-84f6-4062-bf28-25ccf7650c01",
        "showInput": false
      },
      "source": [
        "## GP-EI\n",
        "As a baseline, we compare TuRBO to qEI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921663896,
        "executionStopTime": 1674921754833,
        "originalKey": "8cc7262f-36ac-427f-b7a1-d94b0ceeae5e",
        "requestMsgId": "20905f90-c4bf-4073-9f15-9ac77e1f9c22"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "X_ei = get_initial_points(dim, n_init)\n",
        "Y_ei = torch.tensor(\n",
        "    [eval_objective(x) for x in X_ei], dtype=dtype, device=device\n",
        ").unsqueeze(-1)\n",
        "\n",
        "while len(Y_ei) < len(Y_turbo):\n",
        "    train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
        "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
        "    model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
        "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "    fit_gpytorch_mll(mll)\n",
        "\n",
        "    # Create a batch\n",
        "    ei = qExpectedImprovement(model, train_Y.max())\n",
        "    candidate, acq_value = optimize_acqf(\n",
        "        ei,\n",
        "        bounds=torch.stack(\n",
        "            [\n",
        "                torch.zeros(dim, dtype=dtype, device=device),\n",
        "                torch.ones(dim, dtype=dtype, device=device),\n",
        "            ]\n",
        "        ),\n",
        "        q=batch_size,\n",
        "        num_restarts=NUM_RESTARTS,\n",
        "        raw_samples=RAW_SAMPLES,\n",
        "    )\n",
        "    Y_next = torch.tensor(\n",
        "        [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
        "    ).unsqueeze(-1)\n",
        "\n",
        "    # Append data\n",
        "    X_ei = torch.cat((X_ei, candidate), axis=0)\n",
        "    Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
        "\n",
        "    # Print current status\n",
        "    print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "38f8ac21-d9ae-41f7-ba42-0ff6abde0a2c",
        "showInput": false
      },
      "source": [
        "## Sobol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921754972,
        "executionStopTime": 1674921755010,
        "originalKey": "a6333e87-1fcf-4174-9cb8-111598dd7780",
        "requestMsgId": "629a258e-fa1d-44f8-848c-3335a98e3421"
      },
      "outputs": [],
      "source": [
        "X_Sobol = (\n",
        "    SobolEngine(dim, scramble=True, seed=0)\n",
        "    .draw(len(X_turbo))\n",
        "    .to(dtype=dtype, device=device)\n",
        ")\n",
        "Y_Sobol = torch.tensor(\n",
        "    [eval_objective(x) for x in X_Sobol], dtype=dtype, device=device\n",
        ").unsqueeze(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "e20c8975-af02-4308-a1ef-3f12afb85ffd",
        "showInput": false
      },
      "source": [
        "## Compare the methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921755158,
        "executionStopTime": 1674921757156,
        "originalKey": "b57b38e5-da03-4511-a301-7252eb6c7013",
        "requestMsgId": "7c4c1c41-4852-4498-a42e-14e08dc88afb"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "names = [\"TuRBO-1\", \"EI\", \"Sobol\"]\n",
        "runs = [Y_turbo, Y_ei, Y_Sobol]\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "for name, run in zip(names, runs):\n",
        "    fx = np.maximum.accumulate(run.cpu())\n",
        "    plt.plot(fx, marker=\"\", lw=3)\n",
        "\n",
        "plt.plot([0, len(Y_turbo)], [fun.optimal_value, fun.optimal_value], \"k--\", lw=3)\n",
        "plt.xlabel(\"Function value\", fontsize=18)\n",
        "plt.xlabel(\"Number of evaluations\", fontsize=18)\n",
        "plt.title(\"20D Ackley\", fontsize=24)\n",
        "plt.xlim([0, len(Y_turbo)])\n",
        "plt.ylim([-15, 1])\n",
        "\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.legend(\n",
        "    names + [\"Global optimal value\"],\n",
        "    loc=\"lower center\",\n",
        "    bbox_to_anchor=(0, -0.08, 1, 1),\n",
        "    bbox_transform=plt.gcf().transFigure,\n",
        "    ncol=4,\n",
        "    fontsize=16,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "executionStartTime": 1674921757397,
        "executionStopTime": 1674921757407,
        "originalKey": "81817f68-6383-4446-abc2-7ac698325684",
        "requestMsgId": "f058303d-23d4-4c3a-b5e5-0042b9f1cc05"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "cinder_runtime": true,
      "display_name": "python3",
      "ipyflow_runtime": false,
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
